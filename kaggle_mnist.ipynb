{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.optim import lr_scheduler\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_train = pd.read_csv('csv/mnist/train.csv')\n",
    "read_test = pd.read_csv('csv/mnist/test.csv')\n",
    "\n",
    "train_df = pd.DataFrame(read_train)\n",
    "test_df = pd.DataFrame(read_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 2\n",
    "learning_rate = 0.001\n",
    "dropout_p = 0.5\n",
    "log_interval = 1\n",
    "num_hidden_units = 50\n",
    "num_classes = 10\n",
    "decay_rate = 0.9999\n",
    "max_grad_norm = 5.0\n",
    "n_test = len(test_df)\n",
    "n_pixels = len(test_df.columns)\n",
    "\n",
    "cuda = True\n",
    "cuda = cuda and  torch.cuda.is_available()\n",
    "\n",
    "seed = 42\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class MnistDataset(data.Dataset):\n",
    "    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
    "                 transforms.Normalize(mean=(0.5,), std=(0.5,))])):\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if len(df.columns) == n_pixels:\n",
    "            # test data\n",
    "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = None\n",
    "        else:\n",
    "            # training data\n",
    "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = torch.from_numpy(df.iloc[:,0].values)\n",
    "            \n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])\n",
    "    \n",
    "    \n",
    "    \n",
    "train_set = MnistDataset(file_path='csv/mnist/train.csv',\n",
    "                         transform=transforms.ToTensor(),)\n",
    "\n",
    "test_set = MnistDataset(file_path='csv/mnist/test.csv',\n",
    "                        transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c6729a160549>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         self.features = nn.Sequential(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "          \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(p = 0.25),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1,padding=1),\n",
    "             nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "             nn.BatchNorm2d(64),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1,padding=1),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),         \n",
    "            nn.Dropout(p = 0.25),\n",
    "        )\n",
    "          \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p = 0.25),\n",
    "            nn.Linear(128 * 7 * 7, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.25),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1)% 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.data))\n",
    "\n",
    "            \n",
    "            \n",
    "def test(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data, requires_grad=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += F.cross_entropy(output, target).data\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [6400/42000 (15%)]\tLoss: 0.146345\n",
      "Train Epoch: 0 [12800/42000 (30%)]\tLoss: 0.119844\n",
      "Train Epoch: 0 [19200/42000 (46%)]\tLoss: 0.056904\n",
      "Train Epoch: 0 [25600/42000 (61%)]\tLoss: 0.057727\n",
      "Train Epoch: 0 [32000/42000 (76%)]\tLoss: 0.160663\n",
      "Train Epoch: 0 [38400/42000 (91%)]\tLoss: 0.267308\n",
      "\n",
      "Average loss: 0.0011, Accuracy: 41076/42000 (97.000%)\n",
      "\n",
      "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 0.071886\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 0.123153\n",
      "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 0.105657\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 0.161778\n",
      "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 0.173887\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 0.033028\n",
      "\n",
      "Average loss: 0.0008, Accuracy: 41373/42000 (98.000%)\n",
      "\n",
      "Train Epoch: 2 [6400/42000 (15%)]\tLoss: 0.013622\n",
      "Train Epoch: 2 [12800/42000 (30%)]\tLoss: 0.068517\n",
      "Train Epoch: 2 [19200/42000 (46%)]\tLoss: 0.048287\n",
      "Train Epoch: 2 [25600/42000 (61%)]\tLoss: 0.080676\n",
      "Train Epoch: 2 [32000/42000 (76%)]\tLoss: 0.039632\n",
      "Train Epoch: 2 [38400/42000 (91%)]\tLoss: 0.055838\n",
      "\n",
      "Average loss: 0.0006, Accuracy: 41523/42000 (98.000%)\n",
      "\n",
      "Train Epoch: 3 [6400/42000 (15%)]\tLoss: 0.047452\n",
      "Train Epoch: 3 [12800/42000 (30%)]\tLoss: 0.014397\n",
      "Train Epoch: 3 [19200/42000 (46%)]\tLoss: 0.068732\n",
      "Train Epoch: 3 [25600/42000 (61%)]\tLoss: 0.036596\n",
      "Train Epoch: 3 [32000/42000 (76%)]\tLoss: 0.005573\n",
      "Train Epoch: 3 [38400/42000 (91%)]\tLoss: 0.033957\n",
      "\n",
      "Average loss: 0.0008, Accuracy: 41347/42000 (98.000%)\n",
      "\n",
      "Train Epoch: 4 [6400/42000 (15%)]\tLoss: 0.225439\n",
      "Train Epoch: 4 [12800/42000 (30%)]\tLoss: 0.004724\n",
      "Train Epoch: 4 [19200/42000 (46%)]\tLoss: 0.070004\n",
      "Train Epoch: 4 [25600/42000 (61%)]\tLoss: 0.071565\n",
      "Train Epoch: 4 [32000/42000 (76%)]\tLoss: 0.128863\n",
      "Train Epoch: 4 [38400/42000 (91%)]\tLoss: 0.042930\n",
      "\n",
      "Average loss: 0.0004, Accuracy: 41677/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 5 [6400/42000 (15%)]\tLoss: 0.074325\n",
      "Train Epoch: 5 [12800/42000 (30%)]\tLoss: 0.041134\n",
      "Train Epoch: 5 [19200/42000 (46%)]\tLoss: 0.123711\n",
      "Train Epoch: 5 [25600/42000 (61%)]\tLoss: 0.124543\n",
      "Train Epoch: 5 [32000/42000 (76%)]\tLoss: 0.097451\n",
      "Train Epoch: 5 [38400/42000 (91%)]\tLoss: 0.050088\n",
      "\n",
      "Average loss: 0.0005, Accuracy: 41617/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 6 [6400/42000 (15%)]\tLoss: 0.030906\n",
      "Train Epoch: 6 [12800/42000 (30%)]\tLoss: 0.080097\n",
      "Train Epoch: 6 [19200/42000 (46%)]\tLoss: 0.005463\n",
      "Train Epoch: 6 [25600/42000 (61%)]\tLoss: 0.018728\n",
      "Train Epoch: 6 [32000/42000 (76%)]\tLoss: 0.020844\n",
      "Train Epoch: 6 [38400/42000 (91%)]\tLoss: 0.041169\n",
      "\n",
      "Average loss: 0.0004, Accuracy: 41694/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 7 [6400/42000 (15%)]\tLoss: 0.001508\n",
      "Train Epoch: 7 [12800/42000 (30%)]\tLoss: 0.021907\n",
      "Train Epoch: 7 [19200/42000 (46%)]\tLoss: 0.004827\n",
      "Train Epoch: 7 [25600/42000 (61%)]\tLoss: 0.021572\n",
      "Train Epoch: 7 [32000/42000 (76%)]\tLoss: 0.148167\n",
      "Train Epoch: 7 [38400/42000 (91%)]\tLoss: 0.056785\n",
      "\n",
      "Average loss: 0.0002, Accuracy: 41827/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 8 [6400/42000 (15%)]\tLoss: 0.010512\n",
      "Train Epoch: 8 [12800/42000 (30%)]\tLoss: 0.006259\n",
      "Train Epoch: 8 [19200/42000 (46%)]\tLoss: 0.063813\n",
      "Train Epoch: 8 [25600/42000 (61%)]\tLoss: 0.001163\n",
      "Train Epoch: 8 [32000/42000 (76%)]\tLoss: 0.007368\n",
      "Train Epoch: 8 [38400/42000 (91%)]\tLoss: 0.037055\n",
      "\n",
      "Average loss: 0.0002, Accuracy: 41855/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 9 [6400/42000 (15%)]\tLoss: 0.096098\n",
      "Train Epoch: 9 [12800/42000 (30%)]\tLoss: 0.001380\n",
      "Train Epoch: 9 [19200/42000 (46%)]\tLoss: 0.002686\n",
      "Train Epoch: 9 [25600/42000 (61%)]\tLoss: 0.002005\n",
      "Train Epoch: 9 [32000/42000 (76%)]\tLoss: 0.007562\n",
      "Train Epoch: 9 [38400/42000 (91%)]\tLoss: 0.011713\n",
      "\n",
      "Average loss: 0.0002, Accuracy: 41866/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 10 [6400/42000 (15%)]\tLoss: 0.000435\n",
      "Train Epoch: 10 [12800/42000 (30%)]\tLoss: 0.037642\n",
      "Train Epoch: 10 [19200/42000 (46%)]\tLoss: 0.011020\n",
      "Train Epoch: 10 [25600/42000 (61%)]\tLoss: 0.000960\n",
      "Train Epoch: 10 [32000/42000 (76%)]\tLoss: 0.013855\n",
      "Train Epoch: 10 [38400/42000 (91%)]\tLoss: 0.021966\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 41886/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 11 [6400/42000 (15%)]\tLoss: 0.010059\n",
      "Train Epoch: 11 [12800/42000 (30%)]\tLoss: 0.002626\n",
      "Train Epoch: 11 [19200/42000 (46%)]\tLoss: 0.000142\n",
      "Train Epoch: 11 [25600/42000 (61%)]\tLoss: 0.012205\n",
      "Train Epoch: 11 [32000/42000 (76%)]\tLoss: 0.007684\n",
      "Train Epoch: 11 [38400/42000 (91%)]\tLoss: 0.002492\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 41891/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 12 [6400/42000 (15%)]\tLoss: 0.057117\n",
      "Train Epoch: 12 [12800/42000 (30%)]\tLoss: 0.003212\n",
      "Train Epoch: 12 [19200/42000 (46%)]\tLoss: 0.006300\n",
      "Train Epoch: 12 [25600/42000 (61%)]\tLoss: 0.020944\n",
      "Train Epoch: 12 [32000/42000 (76%)]\tLoss: 0.057040\n",
      "Train Epoch: 12 [38400/42000 (91%)]\tLoss: 0.031419\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 41897/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 13 [6400/42000 (15%)]\tLoss: 0.001498\n",
      "Train Epoch: 13 [12800/42000 (30%)]\tLoss: 0.025373\n",
      "Train Epoch: 13 [19200/42000 (46%)]\tLoss: 0.027516\n",
      "Train Epoch: 13 [25600/42000 (61%)]\tLoss: 0.021087\n",
      "Train Epoch: 13 [32000/42000 (76%)]\tLoss: 0.010035\n",
      "Train Epoch: 13 [38400/42000 (91%)]\tLoss: 0.007437\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 41899/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 14 [6400/42000 (15%)]\tLoss: 0.068881\n",
      "Train Epoch: 14 [12800/42000 (30%)]\tLoss: 0.000521\n",
      "Train Epoch: 14 [19200/42000 (46%)]\tLoss: 0.008995\n",
      "Train Epoch: 14 [25600/42000 (61%)]\tLoss: 0.000720\n",
      "Train Epoch: 14 [32000/42000 (76%)]\tLoss: 0.015405\n",
      "Train Epoch: 14 [38400/42000 (91%)]\tLoss: 0.056544\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 41918/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 15 [6400/42000 (15%)]\tLoss: 0.000178\n",
      "Train Epoch: 15 [12800/42000 (30%)]\tLoss: 0.015536\n",
      "Train Epoch: 15 [19200/42000 (46%)]\tLoss: 0.009010\n",
      "Train Epoch: 15 [25600/42000 (61%)]\tLoss: 0.031802\n",
      "Train Epoch: 15 [32000/42000 (76%)]\tLoss: 0.011564\n",
      "Train Epoch: 15 [38400/42000 (91%)]\tLoss: 0.103176\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 41922/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 16 [6400/42000 (15%)]\tLoss: 0.001432\n",
      "Train Epoch: 16 [12800/42000 (30%)]\tLoss: 0.002803\n",
      "Train Epoch: 16 [19200/42000 (46%)]\tLoss: 0.087595\n",
      "Train Epoch: 16 [25600/42000 (61%)]\tLoss: 0.001070\n",
      "Train Epoch: 16 [32000/42000 (76%)]\tLoss: 0.010250\n",
      "Train Epoch: 16 [38400/42000 (91%)]\tLoss: 0.003196\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 41921/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 17 [6400/42000 (15%)]\tLoss: 0.040894\n",
      "Train Epoch: 17 [12800/42000 (30%)]\tLoss: 0.001104\n",
      "Train Epoch: 17 [19200/42000 (46%)]\tLoss: 0.017787\n",
      "Train Epoch: 17 [25600/42000 (61%)]\tLoss: 0.001450\n",
      "Train Epoch: 17 [32000/42000 (76%)]\tLoss: 0.033431\n",
      "Train Epoch: 17 [38400/42000 (91%)]\tLoss: 0.006909\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 41926/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 18 [6400/42000 (15%)]\tLoss: 0.001598\n",
      "Train Epoch: 18 [12800/42000 (30%)]\tLoss: 0.001515\n",
      "Train Epoch: 18 [19200/42000 (46%)]\tLoss: 0.045956\n",
      "Train Epoch: 18 [25600/42000 (61%)]\tLoss: 0.058812\n",
      "Train Epoch: 18 [32000/42000 (76%)]\tLoss: 0.001545\n",
      "Train Epoch: 18 [38400/42000 (91%)]\tLoss: 0.003367\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 41925/42000 (99.000%)\n",
      "\n",
      "Train Epoch: 19 [6400/42000 (15%)]\tLoss: 0.016971\n",
      "Train Epoch: 19 [12800/42000 (30%)]\tLoss: 0.016407\n",
      "Train Epoch: 19 [19200/42000 (46%)]\tLoss: 0.001853\n",
      "Train Epoch: 19 [25600/42000 (61%)]\tLoss: 0.061393\n",
      "Train Epoch: 19 [32000/42000 (76%)]\tLoss: 0.001484\n",
      "Train Epoch: 19 [38400/42000 (91%)]\tLoss: 0.004680\n",
      "\n",
      "Average loss: 0.0001, Accuracy: 41927/42000 (99.000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "    test(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediciton(data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        data = Variable(data, requires_grad=True)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.cpu().data.max(1, keepdim=True)[1]\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "        \n",
    "    return test_pred\n",
    "\n",
    "\n",
    "test_pred = prediciton(test_loader)\n",
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_set)+1)[:,None], test_pred.numpy()], \n",
    "                      columns=['ImageId', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      3\n",
       "5        6      7\n",
       "6        7      0\n",
       "7        8      3\n",
       "8        9      0\n",
       "9       10      3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
