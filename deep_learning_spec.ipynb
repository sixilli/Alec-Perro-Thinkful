{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fruits 360 Dataset\n",
    "\n",
    "Creating a classifier of fruits utilizing the [fruits 360 dataset](https://www.kaggle.com/moltean/fruits) form kaggle. I had some issues with GPU utilization within Keras. So I recreated to an extent the Keras code below in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,       # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1,        # Randomly zoom image \n",
    "        width_shift_range=0.1,   # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True)    # randomly flip images\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = '../data/fruits-360/Training',\n",
    "    target_size = (64, 64),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = True,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory = '../data/fruits-360/Test',\n",
    "    target_size = (64, 64),\n",
    "    color_mode = 'rgb',\n",
    "    batch_size = 1,\n",
    "    class_mode = None,\n",
    "    shuffle = False,\n",
    "    seed = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf_config = tf.ConfigProto(allow_soft_placement=False)\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "s = tf.Session(config=tf_config)\n",
    "\n",
    "K.set_session(s)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation ='relu', input_shape=(64,64,3)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), padding='Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),padding='Same', activation ='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3),padding='Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1048, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(103, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=53177,\n",
    "                    epochs=30,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=8000,\n",
    "                    workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "# Configuring transformations to be applied to the images to increase\n",
    "# final accuracy.\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(100),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='../data/fruits-360/Training',\n",
    "                                     transform=data_transform)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root='../data/fruits-360/Test',\n",
    "                                    transform=data_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv_layer = nn.Sequential(\n",
    "             nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=0),\n",
    "             nn.ReLU(),\n",
    "             nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=0),\n",
    "             nn.ReLU(),\n",
    "             nn.MaxPool2d(2),\n",
    "             nn.Dropout(p=0.25),\n",
    "             nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=0),\n",
    "             nn.ReLU(),\n",
    "             nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=0),\n",
    "             nn.ReLU(),\n",
    "             nn.MaxPool2d(2),\n",
    "             nn.Dropout(p=0.25)\n",
    "        )\n",
    "        \n",
    "        self.fc_linear_layer = nn.Sequential(\n",
    "             nn.Linear(64*19*19, 500),\n",
    "             nn.ReLU(),\n",
    "             nn.Linear(500, 250),\n",
    "             nn.ReLU(),\n",
    "             nn.Linear(250, 103)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = x.view(-1, 64 * 19 * 19)\n",
    "        x = self.fc_linear_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Model and Train/Eval Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1)% 250 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss))\n",
    "            \n",
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data, requires_grad=True), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss += F.cross_entropy(output, target).data\n",
    "\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [6000/53177 (11%)]\tLoss: 4.646219\n",
      "Train Epoch: 0 [12000/53177 (23%)]\tLoss: 4.416005\n",
      "Train Epoch: 0 [18000/53177 (34%)]\tLoss: 4.393569\n",
      "Train Epoch: 0 [24000/53177 (45%)]\tLoss: 4.136398\n",
      "Train Epoch: 0 [30000/53177 (56%)]\tLoss: 3.519601\n",
      "Train Epoch: 0 [36000/53177 (68%)]\tLoss: 2.453831\n",
      "Train Epoch: 0 [42000/53177 (79%)]\tLoss: 2.370917\n",
      "Train Epoch: 0 [48000/53177 (90%)]\tLoss: 2.319780\n",
      "\n",
      "Average loss: 0.0874, Accuracy: 20191/53177 (37%)\n",
      "\n",
      "Train Epoch: 1 [6000/53177 (11%)]\tLoss: 1.473321\n",
      "Train Epoch: 1 [12000/53177 (23%)]\tLoss: 1.786274\n",
      "Train Epoch: 1 [18000/53177 (34%)]\tLoss: 1.336032\n",
      "Train Epoch: 1 [24000/53177 (45%)]\tLoss: 1.820539\n",
      "Train Epoch: 1 [30000/53177 (56%)]\tLoss: 1.295821\n",
      "Train Epoch: 1 [36000/53177 (68%)]\tLoss: 1.409304\n",
      "Train Epoch: 1 [42000/53177 (79%)]\tLoss: 1.260964\n",
      "Train Epoch: 1 [48000/53177 (90%)]\tLoss: 1.580474\n",
      "\n",
      "Average loss: 0.0445, Accuracy: 35980/53177 (67%)\n",
      "\n",
      "Train Epoch: 2 [6000/53177 (11%)]\tLoss: 0.800236\n",
      "Train Epoch: 2 [12000/53177 (23%)]\tLoss: 1.093324\n",
      "Train Epoch: 2 [18000/53177 (34%)]\tLoss: 0.390699\n",
      "Train Epoch: 2 [24000/53177 (45%)]\tLoss: 1.083729\n",
      "Train Epoch: 2 [30000/53177 (56%)]\tLoss: 1.211807\n",
      "Train Epoch: 2 [36000/53177 (68%)]\tLoss: 1.199944\n",
      "Train Epoch: 2 [42000/53177 (79%)]\tLoss: 0.617570\n",
      "Train Epoch: 2 [48000/53177 (90%)]\tLoss: 0.516793\n",
      "\n",
      "Average loss: 0.0269, Accuracy: 42098/53177 (79%)\n",
      "\n",
      "Train Epoch: 3 [6000/53177 (11%)]\tLoss: 0.320536\n",
      "Train Epoch: 3 [12000/53177 (23%)]\tLoss: 1.530694\n",
      "Train Epoch: 3 [18000/53177 (34%)]\tLoss: 0.919052\n",
      "Train Epoch: 3 [24000/53177 (45%)]\tLoss: 0.262179\n",
      "Train Epoch: 3 [30000/53177 (56%)]\tLoss: 0.261995\n",
      "Train Epoch: 3 [36000/53177 (68%)]\tLoss: 0.531482\n",
      "Train Epoch: 3 [42000/53177 (79%)]\tLoss: 0.398212\n",
      "Train Epoch: 3 [48000/53177 (90%)]\tLoss: 0.456501\n",
      "\n",
      "Average loss: 0.0201, Accuracy: 44807/53177 (84%)\n",
      "\n",
      "Train Epoch: 4 [6000/53177 (11%)]\tLoss: 0.514231\n",
      "Train Epoch: 4 [12000/53177 (23%)]\tLoss: 0.683842\n",
      "Train Epoch: 4 [18000/53177 (34%)]\tLoss: 0.466490\n",
      "Train Epoch: 4 [24000/53177 (45%)]\tLoss: 0.463795\n",
      "Train Epoch: 4 [30000/53177 (56%)]\tLoss: 0.639895\n",
      "Train Epoch: 4 [36000/53177 (68%)]\tLoss: 0.594232\n",
      "Train Epoch: 4 [42000/53177 (79%)]\tLoss: 0.266028\n",
      "Train Epoch: 4 [48000/53177 (90%)]\tLoss: 0.862840\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 30\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)\n",
    "    evaluate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
